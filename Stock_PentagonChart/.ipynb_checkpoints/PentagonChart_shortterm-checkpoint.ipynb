{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========start============\n",
      "startday_price_T-360: 739.480006\n",
      "endday_price_T0: 519.688423833\n",
      "futurerend -0.297224509633\n",
      "GOOG dd_return is: -0.596325579945\n",
      "-0.126822037141 0.576685505636\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 108.9294288\n",
      "endday_price_T0: 108.9294288\n",
      "futurerend 0.0\n",
      "AAPL dd_return is: -0.871414333714\n",
      "-0.297594 0.38110068387\n",
      "===========Cal5Elements PASS============\n",
      "No service for this stock\n",
      "startday_price_T-360: 35.802375\n",
      "endday_price_T0: 46.1039166667\n",
      "futurerend 0.287733472058\n",
      "A1G.F dd_return is: -0.392223553511\n",
      "-0.392223553511 0.599666130827\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 78.6481666667\n",
      "endday_price_T0: 90.405125\n",
      "futurerend 0.14948801519\n",
      "A1H.SG dd_return is: -0.359296584928\n",
      "-0.359296584928 0.63941992535\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 1.11678378378\n",
      "endday_price_T0: 0.829083333333\n",
      "futurerend -0.257615175496\n",
      "A2A.MI dd_return is: -0.63606557377\n",
      "-0.292899408284"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-1-1794e91ec1be>\", line 483, in <module>\n",
      "    future=CalFuture(f[0])\n",
      "  File \"<ipython-input-1-1794e91ec1be>\", line 219, in CalFuture\n",
      "    Futurelist=FuturePredict(stock_ticker)\n",
      "  File \"<ipython-input-1-1794e91ec1be>\", line 173, in FuturePredict\n",
      "    tree = DecisionTree.trainRegressor(output_train_RDD, categoricalFeaturesInfo={},impurity='variance', maxDepth=5, maxBins=30)\n",
      "  File \"/Users/nancywu/sparkhadoop/python/pyspark/mllib/tree.py\", line 255, in trainRegressor\n",
      "    impurity, maxDepth, maxBins, minInstancesPerNode, minInfoGain)\n",
      "  File \"/Users/nancywu/sparkhadoop/python/pyspark/mllib/tree.py\", line 143, in _train\n",
      "    first = data.first()\n",
      "  File \"/Users/nancywu/sparkhadoop/python/pyspark/rdd.py\", line 1318, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.722292993631\n",
      "===========Cal5Elements PASS============\n",
      "No service for this stock\n",
      "startday_price_T-360: 11.1640833333\n",
      "endday_price_T0: 7.43516666667\n",
      "futurerend -0.334010106816\n",
      "A34.F dd_return is: -0.366207396664\n",
      "-0.172865691993 1.51735316552\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 9.68166666667\n",
      "endday_price_T0: 11.5496721311\n",
      "futurerend 0.192942550988\n",
      "A3M.MC dd_return is: -0.506700701978\n",
      "-0.506700701978 1.01932989691\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 0.1521\n",
      "endday_price_T0: 0.19580952381\n",
      "futurerend 0.287373595066\n",
      "A50.SI dd_return is: -0.834328358209\n",
      "-0.483720930233 0.754385964912\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 1.74707142857\n",
      "endday_price_T0: 1.47345454545\n",
      "futurerend -0.156614594368\n",
      "A5F.SG dd_return is: -0.748026948989\n",
      "-0.422075055188 0.814349112426\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 238.786208333\n",
      "endday_price_T0: 231.033666667\n",
      "futurerend -0.0324664549129\n",
      "A60.F dd_return is: -0.287492598112\n",
      "-0.287492598112 0.491568030826\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 245.48\n",
      "endday_price_T0: 301.04\n",
      "futurerend 0.22633208408\n",
      "A60.HM dd_return is: -0.542495701302\n",
      "-0.542495701302 0.14500591516\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 235.1175\n",
      "endday_price_T0: 228.111666667\n",
      "futurerend -0.0297971581585\n",
      "A60.MU dd_return is: -0.273348519362\n",
      "-0.273348519362 0.582552271089\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 266.067004762\n",
      "endday_price_T0: 227.895166667\n",
      "futurerend -0.143467011738\n",
      "A60.SG dd_return is: -0.15804556818\n",
      "-0.15804556818 0.468065743342\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 5.12745454545\n",
      "endday_price_T0: 8.36060416667\n",
      "futurerend 0.630556466674\n",
      "A7Z.F dd_return is: -0.611354989757\n",
      "-0.611354989757 1.47548901232\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 38.9295833333\n",
      "endday_price_T0: 42.8795652174\n",
      "futurerend 0.101464787081\n",
      "A8B.BE dd_return is: -0.741812372415\n",
      "-0.741812372415"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-1-1794e91ec1be>\", line 483, in <module>\n",
      "    future=CalFuture(f[0])\n",
      "  File \"<ipython-input-1-1794e91ec1be>\", line 219, in CalFuture\n",
      "    Futurelist=FuturePredict(stock_ticker)\n",
      "  File \"<ipython-input-1-1794e91ec1be>\", line 173, in FuturePredict\n",
      "    tree = DecisionTree.trainRegressor(output_train_RDD, categoricalFeaturesInfo={},impurity='variance', maxDepth=5, maxBins=30)\n",
      "  File \"/Users/nancywu/sparkhadoop/python/pyspark/mllib/tree.py\", line 255, in trainRegressor\n",
      "    impurity, maxDepth, maxBins, minInstancesPerNode, minInfoGain)\n",
      "  File \"/Users/nancywu/sparkhadoop/python/pyspark/mllib/tree.py\", line 143, in _train\n",
      "    first = data.first()\n",
      "  File \"/Users/nancywu/sparkhadoop/python/pyspark/rdd.py\", line 1318, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3.06530759517\n",
      "===========Cal5Elements PASS============\n",
      "No service for this stock\n",
      "startday_price_T-360: 9.39085106383\n",
      "endday_price_T0: 15.1516666667\n",
      "futurerend 0.613449788915\n",
      "AA dd_return is: -0.617045454545\n",
      "-0.617045454545 0.455072463768\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 166.075714286\n",
      "endday_price_T0: 231.115\n",
      "futurerend 0.391624302169\n",
      "AA.MX dd_return is: -0.523743459648\n",
      "-0.523743459648 0.395751376869\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 8.38625\n",
      "endday_price_T0: 7.12633333333\n",
      "futurerend -0.150236001391\n",
      "AA2.BE dd_return is: -0.33922046285\n",
      "-0.33922046285 0.439088518843\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 0.0921555555556\n",
      "endday_price_T0: 0.0308266315789\n",
      "futurerend -0.665493508307\n",
      "AAA.L dd_return is: -0.99792\n",
      "-0.92 11.4378109453\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 0.12808988764\n",
      "endday_price_T0: 0.2\n",
      "futurerend 0.561403508772\n",
      "AAB.TO dd_return is: -0.846153846154\n",
      "-0.5 0.454545454545\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 19.0358332083\n",
      "endday_price_T0: 29.9112495833\n",
      "futurerend 0.571312863271\n",
      "AAC dd_return is: -0.652737430168\n",
      "-0.652737430168 1.75554187192\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 0.0456666666667\n",
      "endday_price_T0: 0.035\n",
      "futurerend -0.233576642336\n",
      "AAC.V dd_return is: -0.916666666667\n",
      "-0.916666666667 0.428571428571\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 72.4591675833\n",
      "endday_price_T0: 53.2730768462\n",
      "futurerend -0.264784862662\n",
      "AACAY dd_return is: -0.334305555556\n",
      "-0.334305555556 0.526896828583\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 67.0281818182\n",
      "endday_price_T0: 62.7184615385\n",
      "futurerend -0.0642971383501\n",
      "AAD.DE dd_return is: -0.371353077177\n",
      "-0.371353077177 0.532995780591\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 0.937996166667\n",
      "endday_price_T0: 0.952835347826\n",
      "futurerend 0.0158200872101\n",
      "AAEV.L dd_return is: -0.197604790419\n",
      "-0.0979946577363 0.146651428571\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 0.550333333333\n",
      "endday_price_T0: 0.383916666667\n",
      "futurerend -0.3023924894\n",
      "AAFA.F dd_return is: -0.889795918367\n",
      "-0.889795918367 580.875\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 22.0904349565\n",
      "endday_price_T0: 21.8508333333\n",
      "futurerend -0.0108463968075\n",
      "AAGIY dd_return is: -0.321341226732\n",
      "-0.321341226732 0.470467409885\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 7.23263636364\n",
      "endday_price_T0: 10.6868\n",
      "futurerend 0.477580160636\n",
      "AAH3.BE dd_return is: -0.430072173216\n",
      "-0.382536924414 0.232492997199\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 7.26036\n",
      "endday_price_T0: 11.270375\n",
      "futurerend 0.552316276328\n",
      "AAH3.DU dd_return is: -0.427214170692\n",
      "-0.384602076125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-1-1794e91ec1be>\", line 483, in <module>\n",
      "    future=CalFuture(f[0])\n",
      "  File \"<ipython-input-1-1794e91ec1be>\", line 219, in CalFuture\n",
      "    Futurelist=FuturePredict(stock_ticker)\n",
      "  File \"<ipython-input-1-1794e91ec1be>\", line 173, in FuturePredict\n",
      "    tree = DecisionTree.trainRegressor(output_train_RDD, categoricalFeaturesInfo={},impurity='variance', maxDepth=5, maxBins=30)\n",
      "  File \"/Users/nancywu/sparkhadoop/python/pyspark/mllib/tree.py\", line 255, in trainRegressor\n",
      "    impurity, maxDepth, maxBins, minInstancesPerNode, minInfoGain)\n",
      "  File \"/Users/nancywu/sparkhadoop/python/pyspark/mllib/tree.py\", line 143, in _train\n",
      "    first = data.first()\n",
      "  File \"/Users/nancywu/sparkhadoop/python/pyspark/rdd.py\", line 1318, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.206336088154\n",
      "===========Cal5Elements PASS============\n",
      "No service for this stock\n",
      "startday_price_T-360: 39.7883333333\n",
      "endday_price_T0: 28.3239583333\n",
      "futurerend -0.288134084531\n",
      "AAK.F dd_return is: -0.327881930594\n",
      "-0.155975429593 0.637108342771\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 39.9760868696\n",
      "endday_price_T0: 50.3808334167\n",
      "futurerend 0.260274262988\n",
      "AAL dd_return is: -0.362446193058\n",
      "-0.362446193058 0.517278857143\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 560.829166667\n",
      "endday_price_T0: 1148.375\n",
      "futurerend 1.0476377982\n",
      "AAL.L dd_return is: -0.92152999645\n",
      "-0.83981884058 1.74040139616\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 17977.2727273\n",
      "endday_price_T0: 24197.826087\n",
      "futurerend 0.346023195735\n",
      "AALI.JK dd_return is: -0.523167649537\n",
      "-0.483576642336 0.851351351351\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 1.05422857143\n",
      "endday_price_T0: 2.526\n",
      "futurerend 1.39606482736\n",
      "AAM.F dd_return is: -0.794715447154\n",
      "-0.794715447154 3.81566068515\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 25.0583334167\n",
      "endday_price_T0: 28.0666665833\n",
      "futurerend 0.120053202128\n",
      "AAN dd_return is: -0.497528410715\n",
      "-0.497528410715 0.957426173198\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 14.6158333333\n",
      "endday_price_T0: 9.65416666667\n",
      "futurerend -0.339472033753\n",
      "AAOI dd_return is: -0.694383661561\n",
      "-0.450910706353 1.6861575179\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 4.75642857143\n",
      "endday_price_T0: 4.46222222222\n",
      "futurerend -0.0618544659692\n",
      "AAR-UN.TO dd_return is: -0.231638418079\n",
      "-0.212643678161 0.26392251816\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 0.775059846154\n",
      "endday_price_T0: 0.817747923077\n",
      "futurerend 0.0550771364752\n",
      "AATG.L dd_return is: -0.24137798142\n",
      "-0.24137798142 0.315165753425\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 0.708571428571\n",
      "endday_price_T0: 0.936363636364\n",
      "futurerend 0.321480938416\n",
      "AAU dd_return is: -0.849230769231\n",
      "-0.6171875 1.42\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 2.856\n",
      "endday_price_T0: 2.82258333333\n",
      "futurerend -0.0117005135387\n",
      "AAU.SG dd_return is: -0.812721490232\n",
      "-0.428494333513 0.601555747623\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 7.058\n",
      "endday_price_T0: 5.45384615385\n",
      "futurerend -0.227281644397\n",
      "AAV.TO dd_return is: -0.39921976593\n",
      "-0.263480392157 0.766233766234\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 0.69136168\n",
      "endday_price_T0: 0.676656207547\n",
      "futurerend -0.021270303053\n",
      "AAVC.L dd_return is: -0.182449494949\n",
      "-0.0587829001376 0.0798381679389\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 0.00193445652174\n",
      "endday_price_T0: 1.185\n",
      "futurerend 611.575153116\n",
      "AAWC dd_return is: -0.999352941176\n",
      "-0.999352941176 8499.0\n",
      "===========Cal5Elements PASS============\n",
      "startday_price_T-360: 0.23825\n",
      "endday_price_T0: 0.419333333333\n",
      "futurerend 0.760055963624\n",
      "AAX.AX dd_return is: -0.956043956044\n",
      "-0.586538461538"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-1-1794e91ec1be>\", line 483, in <module>\n",
      "    future=CalFuture(f[0])\n",
      "  File \"<ipython-input-1-1794e91ec1be>\", line 219, in CalFuture\n",
      "    Futurelist=FuturePredict(stock_ticker)\n",
      "  File \"<ipython-input-1-1794e91ec1be>\", line 173, in FuturePredict\n",
      "    tree = DecisionTree.trainRegressor(output_train_RDD, categoricalFeaturesInfo={},impurity='variance', maxDepth=5, maxBins=30)\n",
      "  File \"/Users/nancywu/sparkhadoop/python/pyspark/mllib/tree.py\", line 255, in trainRegressor\n",
      "    impurity, maxDepth, maxBins, minInstancesPerNode, minInfoGain)\n",
      "  File \"/Users/nancywu/sparkhadoop/python/pyspark/mllib/tree.py\", line 143, in _train\n",
      "    first = data.first()\n",
      "  File \"/Users/nancywu/sparkhadoop/python/pyspark/rdd.py\", line 1318, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.6\n",
      "===========Cal5Elements PASS============\n",
      "No service for this stock\n",
      "startday_price_T-360: 23.6050000833\n",
      "endday_price_T0: 24.800833375\n",
      "futurerend 0.0506601689237\n",
      "AB dd_return is: -0.481481544353\n",
      "-0.481481544353 0.803005219978\n",
      "===========Cal5Elements PASS============\n",
      "=======ES writing pass=======\n",
      "[[u'GOOG', [5.0, 2.0, 2.5, 4.0, 4.0]], [u'AAPL', [4.0, 3.0, 2.0, 5.0, 3.0]], [u'A1G.F', [4.0, 5.0, 3.0, 1.0, 2.0]], [u'A1H.SG', [3.0, 4.0, 3.0, 0.0, 2.0]], [u'A2A.MI', [5.0, 2.0, 1.25, 4.0, 3.0]], [u'A34.F', [5.0, 2.0, 1.75, 0.0, 4.0]], [u'A3M.MC', [2.0, 4.0, 2.5, 4.0, 2.0]], [u'A50.SI', [2.0, 5.0, 0.75, 4.0, 2.0]], [u'A5F.SG', [2.0, 2.0, 2.5, 0.0, 2.0]], [u'A60.F', [4.0, 3.0, 3.5, 1.0, 3.0]], [u'A60.HM', [2.0, 5.0, 1.25, 0.0, 2.0]], [u'A60.MU', [5.0, 3.0, 3.5, 0.0, 3.0]], [u'A60.SG', [5.0, 2.0, 3.5, 0.0, 4.0]], [u'A7Z.F', [2.0, 5.0, 1.25, 0.0, 2.0]], [u'A8B.BE', [4.0, 4.0, 2.5, 0.0, 2.0]], [u'AA', [2.0, 5.0, 3.0, 4.0, 2.0]], [u'AA.MX', [2.0, 5.0, 2.5, 2.0, 2.0]], [u'AA2.BE', [4.0, 2.0, 1.75, 0.0, 2.0]], [u'AAA.L', [5.0, 1.0, 0.75, 2.0, 2.0]], [u'AAB.TO', [2.0, 5.0, 0.75, 3.0, 2.0]], [u'AAC', [3.0, 5.0, 2.5, 3.0, 2.0]], [u'AAC.V', [1.0, 2.0, 0.75, 2.0, 2.0]], [u'AACAY', [5.0, 2.0, 3.0, 2.0, 2.0]], [u'AAD.DE', [4.0, 3.0, 3.0, 2.0, 2.0]], [u'AAEV.L', [4.0, 4.0, 2.25, 2.0, 4.0]], [u'AAFA.F', [5.0, 2.0, 1.5, 1.0, 2.0]], [u'AAGIY', [4.0, 3.0, 3.0, 3.0, 2.0]], [u'AAH3.BE', [2.0, 5.0, 3.0, 0.0, 2.0]], [u'AAH3.DU', [2.0, 5.0, 3.0, 1.0, 2.0]], [u'AAK.F', [5.0, 2.0, 3.0, 0.0, 4.0]], [u'AAL', [3.0, 5.0, 3.5, 4.0, 2.0]], [u'AAL.L', [1.0, 5.0, 2.0, 4.0, 2.0]], [u'AALI.JK', [2.0, 5.0, 3.0, 4.0, 2.0]], [u'AAM.F', [1.0, 5.0, 1.25, 1.0, 2.0]], [u'AAN', [4.0, 4.0, 3.5, 4.0, 2.0]], [u'AAOI', [3.0, 2.0, 3.0, 3.0, 2.0]], [u'AAR-UN.TO', [4.0, 3.0, 3.5, 3.0, 3.0]], [u'AATG.L', [3.0, 4.0, 2.25, 2.0, 3.0]], [u'AAU', [2.0, 5.0, 2.0, 3.0, 2.0]], [u'AAU.SG', [4.0, 3.0, 2.0, 1.0, 2.0]], [u'AAV.TO', [5.0, 2.0, 3.0, 4.0, 3.0]], [u'AAVC.L', [4.0, 3.0, 2.25, 2.0, 3.0]], [u'AAWC', [5.0, 5.0, 0.75, 3.0, 2.0]], [u'AAX.AX', [2.0, 5.0, 2.0, 3.0, 2.0]], [u'AB', [3.0, 4.0, 3.5, 3.0, 2.0]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-1-1794e91ec1be>\", line 483, in <module>\n",
      "    future=CalFuture(f[0])\n",
      "  File \"<ipython-input-1-1794e91ec1be>\", line 219, in CalFuture\n",
      "    Futurelist=FuturePredict(stock_ticker)\n",
      "  File \"<ipython-input-1-1794e91ec1be>\", line 173, in FuturePredict\n",
      "    tree = DecisionTree.trainRegressor(output_train_RDD, categoricalFeaturesInfo={},impurity='variance', maxDepth=5, maxBins=30)\n",
      "  File \"/Users/nancywu/sparkhadoop/python/pyspark/mllib/tree.py\", line 255, in trainRegressor\n",
      "    impurity, maxDepth, maxBins, minInstancesPerNode, minInfoGain)\n",
      "  File \"/Users/nancywu/sparkhadoop/python/pyspark/mllib/tree.py\", line 143, in _train\n",
      "    first = data.first()\n",
      "  File \"/Users/nancywu/sparkhadoop/python/pyspark/rdd.py\", line 1318, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#\n",
    "#Author: WU Nan\n",
    "#Date: 2017.02.21\n",
    "#Description: This is the csv to csv programme file \n",
    "#It calculates the pentagon chart five elements numbers for each stock.\n",
    "#\n",
    "#SHORT TERM VERSION\n",
    "#\n",
    "from __future__ import print_function\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "import sys\n",
    "from operator import add\n",
    "from pyspark import SparkContext\n",
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from pyspark.mllib.regression import LinearRegressionModel, LinearRegressionWithSGD\n",
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n",
    "from pyspark.mllib.regression import IsotonicRegression, IsotonicRegressionModel\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "\n",
    "##################-------------------get_csv_data---------------------################################--------------------\n",
    "def get_csv_data(filename):\n",
    "            filename = \"file:/Users/nancywu/sparkhadoop/datatest/Stock/\"+filename+\".csv\"\n",
    "            File = sc.textFile(filename)\n",
    "            File.map(lambda line: line.split(\",\"))\n",
    "            File.filter(lambda line: len(line) > 0)\n",
    "            File.map(lambda line: (line[0], line[1]))\n",
    "            data = File.collect()\n",
    "            stock_text = [d.split(\",\") for d in data]\n",
    "            #From backward of Period of present date (90 days before 2016.4.1) to present date 2016.4.1\n",
    "            #historical period you want to choose\n",
    "            period = 360*3\n",
    "            #1:openprice\n",
    "            #2:highprice\n",
    "            #3:lowprice\n",
    "            #4:closeprice\n",
    "            #5:volume\n",
    "            #6:Adjcloseprice\n",
    "            if (len(stock_text)<period): period=len(stock_text)-1\n",
    "            open_price = [round(float(stock_text[i][1]),10) for i in range(period,0,-1)]\n",
    "            close_price = [round(float(stock_text[i][4]),10) for i in range(period,0,-1)]\n",
    "            volume=[long(stock_text[i][5]) for i in range (period, 0,-1)]\n",
    "            date=[\"Date\"]\n",
    "            [date.append(stock_text[i][0]) for i in range(period,0,-1)]\n",
    "            return open_price,close_price,volume,date\n",
    "\n",
    "def get_csv_data_30(filename):\n",
    "            filename = \"file:/Users/nancywu/sparkhadoop/datatest/Stock/\"+filename+\".csv\"\n",
    "            File = sc.textFile(filename)\n",
    "            File.map(lambda line: line.split(\",\"))\n",
    "            File.filter(lambda line: len(line) > 0)\n",
    "            File.map(lambda line: (line[0], line[1]))\n",
    "            data = File.collect()\n",
    "            stock_text = [d.split(\",\") for d in data]\n",
    "            #From backward of Period of present date (90 days before 2016.4.1) to present date 2016.4.1\n",
    "            #historical period you want to choose\n",
    "            period = 30\n",
    "            #1:openprice\n",
    "            #2:highprice\n",
    "            #3:lowprice\n",
    "            #4:closeprice\n",
    "            #5:volume\n",
    "            #6:Adjcloseprice\n",
    "            if (len(stock_text)<period): period=len(stock_text)-1\n",
    "            open_price = [round(float(stock_text[i][1]),10) for i in range(period,0,-1)]\n",
    "            close_price = [round(float(stock_text[i][4]),10) for i in range(period,0,-1)]\n",
    "            volume=[long(stock_text[i][5]) for i in range (period, 0,-1)]\n",
    "            date=[\"Date\"]\n",
    "            [date.append(stock_text[i][0]) for i in range(period,0,-1)]\n",
    "            return open_price,close_price,volume,date\n",
    "        \n",
    "def get_csv_data_90(filename):\n",
    "            filename = \"file:/Users/nancywu/sparkhadoop/datatest/Stock/\"+filename+\".csv\"\n",
    "            File = sc.textFile(filename)\n",
    "            File.map(lambda line: line.split(\",\"))\n",
    "            File.filter(lambda line: len(line) > 0)\n",
    "            File.map(lambda line: (line[0], line[1]))\n",
    "            data = File.collect()\n",
    "            stock_text = [d.split(\",\") for d in data]\n",
    "            #From backward of Period of present date (90 days before 2016.4.1) to present date 2016.4.1\n",
    "            #historical period you want to choose\n",
    "            period = 90\n",
    "            #1:openprice\n",
    "            #2:highprice\n",
    "            #3:lowprice\n",
    "            #4:closeprice\n",
    "            #5:volume\n",
    "            #6:Adjcloseprice\n",
    "            if (len(stock_text)<period): period=len(stock_text)-1\n",
    "            open_price = [round(float(stock_text[i][1]),10) for i in range(period,0,-1)]\n",
    "            close_price = [round(float(stock_text[i][4]),10) for i in range(period,0,-1)]\n",
    "            volume=[long(stock_text[i][5]) for i in range (period, 0,-1)]\n",
    "            date=[\"Date\"]\n",
    "            [date.append(stock_text[i][0]) for i in range(period,0,-1)]\n",
    "            return open_price,close_price,volume,date\n",
    "        \n",
    "def get_csv_data_360(filename):\n",
    "            filename = \"file:/Users/nancywu/sparkhadoop/datatest/Stock/\"+filename+\".csv\"\n",
    "            File = sc.textFile(filename)\n",
    "            File.map(lambda line: line.split(\",\"))\n",
    "            File.filter(lambda line: len(line) > 0)\n",
    "            File.map(lambda line: (line[0], line[1]))\n",
    "            data = File.collect()\n",
    "            stock_text = [d.split(\",\") for d in data]\n",
    "            #From backward of Period of present date (90 days before 2016.4.1) to present date 2016.4.1\n",
    "            #historical period you want to choose\n",
    "            period = 360\n",
    "            #1:openprice\n",
    "            #2:highprice\n",
    "            #3:lowprice\n",
    "            #4:closeprice\n",
    "            #5:volume\n",
    "            #6:Adjcloseprice\n",
    "            if (len(stock_text)<period): period=len(stock_text)-1\n",
    "            open_price = [round(float(stock_text[i][1]),10) for i in range(period,0,-1)]\n",
    "            close_price = [round(float(stock_text[i][4]),10) for i in range(period,0,-1)]\n",
    "            volume=[long(stock_text[i][5]) for i in range (period, 0,-1)]\n",
    "            date=[\"Date\"]\n",
    "            [date.append(stock_text[i][0]) for i in range(period,0,-1)]\n",
    "            return open_price,close_price,volume,date\n",
    "        \n",
    "##################-------------------History------------------------------################################--------------------\n",
    "def CalHistory(stock_ticker):\n",
    "    open_price,close_price, volume,date= get_csv_data_360(stock_ticker)\n",
    "    if (len(close_price)>=3):\n",
    "        startday=close_price[1]\n",
    "        endday=close_price[-1]\n",
    "        histrend=(endday-startday)/startday\n",
    "        #print (\"startday_price_T-360:\", startday)\n",
    "        #print (\"endday_price_T0:\",endday)\n",
    "        #print (\"histrend\",histrend)\n",
    "        if (histrend<-0.8):\n",
    "            his=1.0\n",
    "        elif (histrend<-0.1 and histrend>-0.8):\n",
    "            his=2.0\n",
    "        elif (histrend>-0.1 and histrend <0.01):\n",
    "            his=3.0\n",
    "        elif (histrend>0.01 and histrend <0.2):\n",
    "            his =4.0\n",
    "        else:\n",
    "            his=5.0\n",
    "        return his\n",
    "    else:\n",
    "        his=2.5\n",
    "        return his\n",
    "        \n",
    "\n",
    "##################-------------------Future----------------------------################################--------------------\n",
    "\n",
    "def FuturePredict(stock_ticker):\n",
    "    #Use Regression model Linear Regression Model do predict\n",
    "    open_price_train, close_price_train, volume, date= get_csv_data_360(stock_ticker)\n",
    "    output=[]\n",
    "    for i in range(1,len(date)-2):\n",
    "        #这里用每天的open price作为target 用close price 作为训练features特征\n",
    "        #⚠️此处应该要改，这里先试验\n",
    "        tmp = LabeledPoint(label=close_price_train[i+1],features=[open_price_train[i]])\n",
    "        output.append(tmp)\n",
    "        \n",
    "    output_train_RDD=sc.parallelize(output).cache()                                                          \n",
    "    #lrm=LinearRegressionWithSGD.train(output_train_RDD,step=0.001,iterations=100000)\n",
    "    tree = DecisionTree.trainRegressor(output_train_RDD, categoricalFeaturesInfo={},impurity='variance', maxDepth=5, maxBins=30)\n",
    "    #forest = RandomForest.trainRegressor(output_train_RDD, categoricalFeaturesInfo={}, numTrees=3, featureSubsetStrategy=\"auto\", impurity='variance', maxDepth=5, maxBins=30)\n",
    "    #gradient = GradientBoostedTrees.trainRegressor(output_train_RDD, categoricalFeaturesInfo={}, numIterations=10)\n",
    "    #es_modelname=['lrm','tree','forest','gradient']\n",
    "    x=0\n",
    "    err=1000\n",
    "    #此处选择最优rdd 做predict\n",
    "    output_model_RDD=tree\n",
    "    \n",
    "    \"\"\"\n",
    "    if not tree:\n",
    "        output_model_RDD=lrm\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    for model in [lrm, tree, forest, gradient]:\n",
    "        predictions = model.predict(output_train_RDD.map(lambda x: x.features))\n",
    "        labelsAndPredictions = output_train_RDD.map(lambda lp: lp.label).zip(predictions)\n",
    "        MSE = (labelsAndPredictions.map(lambda (v, p): (v - p) * (v - p)).sum() /float(output_train_RDD.count()))**0.5\n",
    "        if (err>MSE):\n",
    "            err=MSE\n",
    "            output_model_RDD=model\n",
    "            #output_model=es_modelname[x]\n",
    "        x+=1\n",
    "    print(\"output_model:\",output_model)\n",
    "    #output_model_RDD=tree\n",
    "    \"\"\"\n",
    "    train_len=len(close_price_train)\n",
    "    output=[]\n",
    "    S1=output_model_RDD.predict([open_price_train[train_len-1]])\n",
    "    #predictlist = [[\"startday\"+date[train_len],\"Predictprice\"]]\n",
    "    #tmpdate=1\n",
    "    short_period=30\n",
    "    for i in range (short_period+1,1,-1):\n",
    "        #tmp = [str(tmpdate)+\"day\",S1]\n",
    "        output.append(S1)\n",
    "        #predictlist.append(tmp)\n",
    "        #此处是一个短的周期，其保证比如short period=30days, 此predict在上一个30天的循环周期，保证波动一致性\n",
    "        S0=(S1+close_price_train[i+short_period])*0.5\n",
    "        S1=output_model_RDD.predict([S0])\n",
    "        #tmpdate+=1\n",
    "    #print (\"\\n============PredictList=============\\n\")\n",
    "    #print (predictlist)\n",
    "    return output\n",
    "\n",
    "def CalFuture(stock_ticker): #待修改\n",
    "    Futurelist=FuturePredict(stock_ticker)\n",
    "    #print (\"\\n============FutureList=============\\n\")\n",
    "    #print(Futurelist)\n",
    "    startday=Futurelist[0]\n",
    "    endday=Futurelist[-1]\n",
    "    \n",
    "    futurerend=(endday-startday)/startday\n",
    "    print (\"startday_price_T-360:\", startday)\n",
    "    print (\"endday_price_T0:\",endday)\n",
    "    print (\"futurerend\",futurerend)\n",
    "    if (futurerend<-0.5):\n",
    "        future=1.0\n",
    "    elif (futurerend<-0.1 and futurerend>-0.5):\n",
    "        future=2.0\n",
    "    elif (futurerend>-0.1 and futurerend <0.01):\n",
    "        future=3.0\n",
    "    elif (futurerend>0.01 and futurerend <0.2):\n",
    "        future=4.0\n",
    "    else:\n",
    "        future=5.0\n",
    "    return future\n",
    "    \n",
    "    \n",
    "##################-------------------Health------------------------------################################--------------------\n",
    "\"\"\"Health Cal START\"\"\"\n",
    "def normal_distribution_test(open_price,close_price):\n",
    "        ##risk distance round精度调整\n",
    "            risk_assessment_initial = list(map(lambda x: round(float(x[0]-x[1]),2), zip(open_price, close_price)))\n",
    "            ##\n",
    "            #print(\"====risk assessment initial======\")\n",
    "            tmp=sc.parallelize(risk_assessment_initial)\n",
    "            Change_initial = tmp.map(lambda distance: (distance, 1)).reduceByKey(lambda a, b: a + b)\n",
    "            Change_list=Change_initial.collect()\n",
    "            distance_list=[]\n",
    "            frequency_list=[]\n",
    "            for (distance,frequency) in Change_list:\n",
    "            #这里限制了波动噪声。为ND_test做准备\n",
    "                if (frequency<len(risk_assessment_initial)*0.5):\n",
    "                    distance_list.append(distance)\n",
    "                    frequency_list.append(frequency)\n",
    "            #3 methods of statistics to test how distribution it is.\n",
    "            #Make risk range for particular stock\n",
    "            x = frequency_list\n",
    "            signal=1.5\n",
    "            if (len(x)<=20): return signal, Change_list\n",
    "            \n",
    "            shapiro_results = scipy.stats.shapiro(x)\n",
    "            a1=shapiro_results[0]\n",
    "            a2=round(shapiro_results[1],8)\n",
    "            #matrix_sw = [['', 'DF', 'Test Statistic_SW', 'p-value'],['Sample Data', len(x) - 1, a1, a2]]\n",
    "            #print(matrix_sw)\n",
    "            #shapiro_result more close to 1 more probabily of normal distribution it is\n",
    "            #####\n",
    "            ks_results = scipy.stats.kstest(x, cdf='norm')\n",
    "            b1=ks_results[0]\n",
    "            b2=round(ks_results[1],8)\n",
    "            #matrix_ks = [['', 'DF', 'Test Statistic_KS', 'p-value'],['Sample Data', len(x) - 1, b1, b2]]\n",
    "            #print(matrix_ks)\n",
    "            ###\n",
    "            dagostino_results = scipy.stats.mstats.normaltest(x)\n",
    "            c1=dagostino_results[0]\n",
    "            c2=round(dagostino_results[1],8)\n",
    "            #matrix_dp = [['', 'DF', 'Test Statistic_dp', 'p-value'],['Sample Data', len(x) - 1, c1, c2]]\n",
    "            #print(matrix_dp)\n",
    "            ###########risk_ND_signal##############\n",
    "            if (abs(a1-a2)>0.8 and (abs(b1-b2)>0.8 and b2<0.0005) and (abs(c1-c2)>0.8 and c2<0.0005)):\n",
    "                #normal distribution. low risk\n",
    "                signal=5\n",
    "            elif ((abs(a1-a2)>0.8 and (abs(b1-b2)>0.8 and b2<0.0005))or (abs(a1-a2)>0.8 and (abs(c1-c2)>0.8 and c2<0.0005)) or ((abs(b1-b2)>0.8 and b2<0.0005) and (abs(c1-c2)>0.8 and c2<0.0005))):\n",
    "                signal=4\n",
    "            elif (abs(a1-a2)>1 or abs(b1-b2)>1 or abs(c1-c2)>1): \n",
    "                signal=3\n",
    "            else:\n",
    "                #not normal distribution. high risk\n",
    "                signal =2\n",
    "            return signal,Change_list\n",
    "        \n",
    "#Max_drawdown   \n",
    "#回撤结束时间点\n",
    "#close_price是需要探测的最大回撤率的时间范围内的价格区间，close_price=[price1,price2,price3],时间标度:day_i,day_i+1\n",
    "# 回撤开始的时间点\n",
    "def max_drawdown_test(close_price):\n",
    "        #dd:drawdown\n",
    "        risk_DD_signal=2.5\n",
    "        if (len(close_price)<=20): return risk_DD_signal, 0\n",
    "        i = np.argmax(np.maximum.accumulate(close_price) - close_price)\n",
    "        j = np.argmax(close_price[:i])\n",
    "        dd_return =(float(close_price[i]) /close_price[j]) - 1\n",
    "        ####回撤signal_setting##########\n",
    "        if (abs(dd_return)<0.05):\n",
    "            risk_DD_signal=5.0\n",
    "        elif (abs (dd_return)<0.1):\n",
    "            risk_DD_signal=4.0\n",
    "        elif (abs (dd_return)<0.3):\n",
    "            risk_DD_signal=3.0\n",
    "        elif (abs (dd_return)<0.5):\n",
    "            risk_DD_signal=2.0\n",
    "        elif (abs (dd_return)<0.8):\n",
    "            risk_DD_signal=1.0\n",
    "        else:\n",
    "            risk_DD_signal=0\n",
    "        return risk_DD_signal, dd_return\n",
    "\n",
    "#Value at Risk\n",
    "#Example:With 99% confidence, we expect that the worst daily loss will not exceed 8.2%.\n",
    "#Or, if we invest $100, we are 99% confident that our worst daily loss will not exceed $8.2.\n",
    "#Read more: An Introduction To Value at Risk (VAR) | Investopedia http://www.investopedia.com/articles/04/092904.asp#ixzz4Smo70sV3 \n",
    "def historicalVaR(close_price,confidenceLevel):\n",
    "    returnRate=[]\n",
    "    [returnRate.append((float(close_price[j+1])-float(close_price[j]))/float(close_price[j])) for j in range(0,len(close_price)-1,1)]\n",
    "    n=len(returnRate)\n",
    "    m=int(n*(1-confidenceLevel))\n",
    "    returnRate.sort()\n",
    "    print (returnRate,n)\n",
    "    result=returnRate[m]\n",
    "    return result    \n",
    "    \n",
    "\n",
    "def risk_assessment(filename):\n",
    "    \"\"\"\n",
    "        filename=stock_ticker\n",
    "    \"\"\"\n",
    "    ###此处可以优化\n",
    "    open_price,close_price, volume, date= get_csv_data(f[0])\n",
    "    risk_ND_signal, Change_list=normal_distribution_test(open_price[1:],close_price[1:])\n",
    "    risk_DD_signal, dd_return = max_drawdown_test(close_price[1:])\n",
    "    #risk_VaR_signal, result=\n",
    "    print (filename, \"dd_return is:\",dd_return)\n",
    "    return Change_list,risk_DD_signal, risk_ND_signal\n",
    "\n",
    "                    \n",
    "def CalRiskRate(stock_ticker):\n",
    "    #####Risk rate preparation\n",
    "    ####Risk level set up by Customer set \n",
    "    ###5:100%; 4:80%; 3:60%; 2,1,0\n",
    "    #risk_w_VaR=0.3\n",
    "    ######risk_w_ND+risk_w_DD+...+other risk_w_assess=100%\n",
    "    risk_w_ND=0.5\n",
    "    risk_w_DD=0.5\n",
    "    Change_list_Normal_Distribution, risk_DD_signal, risk_ND_signal = risk_assessment(stock_ticker)\n",
    "    risk_rate=risk_DD_signal*risk_w_DD + risk_ND_signal*risk_w_ND\n",
    "    return risk_rate\n",
    "\"\"\"Health Cal END\"\"\"\n",
    "##################--------------------Popularity-----------------------------################################--------------------\n",
    "\n",
    "\"\"\"Popularity Cal START\"\"\"\n",
    "def CalPop(stock_ticker):\n",
    "    ###此处可以优化\n",
    "    open_price,close_price, volume, date= get_csv_data(stock_ticker)\n",
    "    avg=np.average(volume[1:])\n",
    "    if (avg<50):\n",
    "        pop=0.0\n",
    "    elif (avg>50 and avg<500):\n",
    "        pop=1.0\n",
    "    elif (avg>500 and avg<50000):\n",
    "        pop=2.0\n",
    "    elif (avg >50000 and avg <500000):\n",
    "        pop=3.0\n",
    "    elif (avg>500000 and avg<50000000):\n",
    "        pop=4.0\n",
    "    else:\n",
    "        pop=5.0\n",
    "    return pop\n",
    "\n",
    "\"\"\"Popularity Cal END\"\"\"\n",
    "##################------------------------Return-------------------------################################--------------------\n",
    "\n",
    "\"\"\"Return Cal START\"\"\"\n",
    "#short_term = 90days  long_term=2-3years\n",
    "#max_dd:最大回撤率\n",
    "#max_gain:最大回报率\n",
    "def CalReturn(stock_ticker):\n",
    "    open_price,close_price, volume, date= get_csv_data_360(stock_ticker)\n",
    "    r=1.0\n",
    "    close_price=close_price[1:]\n",
    "    i = np.argmax(np.maximum.accumulate(close_price) - close_price)\n",
    "    ii=np.argmax(close_price-np.minimum.accumulate(close_price))\n",
    "    if (len(close_price)>7 and close_price[:i]):#7days 1 week\n",
    "        j = np.argmax(close_price[:i])\n",
    "        jj= np.argmin(close_price[:i])\n",
    "        max_dd =(float(close_price[i]) /close_price[j]) - 1\n",
    "        max_gain =(float(close_price[ii]) /close_price[jj]) - 1\n",
    "        print (max_dd,max_gain)\n",
    "        if (max_dd>-0.1 and max_gain>0.3):\n",
    "                r=5.0\n",
    "        elif (max_dd>-0.2 and max_gain>0.1):\n",
    "                r=4.0\n",
    "        elif (max_dd>-0.3 and max_gain>0.05):\n",
    "                r=3.0\n",
    "        elif (max_dd>-0.5 or max_gain>0.01):\n",
    "                r=2.0\n",
    "        else:\n",
    "                r=1.0\n",
    "    return r\n",
    "\n",
    "\"\"\"Return Cal END\"\"\"\n",
    "\n",
    "\"\"\" 股票详细资料字典\n",
    "\"\"\"\n",
    "def StockDict():\n",
    "    stockdict= {}\n",
    "    File = sc.textFile(\"file:/Users/nancywu/sparkhadoop/datatest/stockdetails_all.csv\")\n",
    "    File.map(lambda line: line.split(\",\"))\n",
    "    File.filter(lambda line: len(line) > 0)\n",
    "    File.map(lambda line: (line[0], line[1]))\n",
    "    data = File.collect()\n",
    "    dic = [d.split(\",\") for d in data]\n",
    "    #print (dic)\n",
    "    for i in dic:\n",
    "        stockdict[i[0]] = [i[1:]]\n",
    "    return stockdict\n",
    "\n",
    "\"\"\"Write Details of Stock into Elasticsearch\n",
    "   with 5 elements of each pentagon stock chart as well\n",
    "\"\"\"\n",
    "def writeToElastic(fileindex,es,stockdict,StockPlist):\n",
    "    #filename=stock_ticker\n",
    "    df=StockPlist\n",
    "    j = 0\n",
    "    actions = []\n",
    "    count = int(len(df))\n",
    "    while (j < count):\n",
    "        tmplist=stockdict.get(df[j][0])\n",
    "        print (\"tmplist\",tmplist)\n",
    "        if tmplist:\n",
    "            action = {\n",
    "                       \"_index\": fileindex, # 这里不可以是大写都是小写\n",
    "                       \"_type\": df[j][0],\n",
    "                       \"_id\": j,\n",
    "                       \"_source\": {\n",
    "                                   \"ticker\":df[j][0],\n",
    "                                   \"details\":tmplist[0],\n",
    "                                   \"pentagon\":df[j][1],\n",
    "                                    }\n",
    "                       }\n",
    "            print(action)\n",
    "            actions.append(action)\n",
    "            j += 1\n",
    "        if (len(actions) == 180):\n",
    "            helpers.bulk(es, actions)\n",
    "            del actions[0:len(actions)]\n",
    "            \n",
    "    if (len(actions) >0 ):\n",
    "            helpers.bulk(es, actions)\n",
    "            del actions[0:len(actions)]\n",
    "\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    #sc = SparkContext(appName=\"Monte Carlo\")\n",
    "    #short term= 90days  long term= 360days \n",
    "    Ticker = sc.textFile(\"file:/Users/nancywu/sparkhadoop/datatest/Ticker_50.csv\")\n",
    "    filelist = Ticker.map(lambda f: f.split(\",\")).collect()\n",
    "    #print(filelist)\n",
    "    es = Elasticsearch([\"http://127.0.0.1:9200\"])\n",
    "    StockPlist=[]\n",
    "    print(\"===========start============\")\n",
    "    stockdict=StockDict()\n",
    "    for f in filelist:\n",
    "        try:\n",
    "            tmplist=[f[0]]\n",
    "            name=f[0]+\"_pentagon.csv\"\n",
    "            #output_predict,modelname = generation_output(f[0])\n",
    "            \"\"\"history, future, health(risk), return, popularity\"\"\"\n",
    "            history=CalHistory(f[0])\n",
    "            future=CalFuture(f[0])\n",
    "            health=CalRiskRate(f[0])\n",
    "            popularity=CalPop(f[0])\n",
    "            r=CalReturn(f[0])\n",
    "            print (\"===========Cal5Elements PASS============\")\n",
    "            tmplist.append([history,future,health,popularity,r])\n",
    "            StockPlist.append(tmplist)\n",
    "            #sc.parallelize(output_predict).repartition(1).saveAsTextFile(\"file:/Users/nancywu/sparkhadoop/datatest_result/\" + name)\n",
    "        except:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            print(\"No service for this stock\")\n",
    "    #writeToElastic('stockshortermd',es,stockdict,StockPlist)\n",
    "    print(\"=======ES writing pass=======\")\n",
    "    print (StockPlist)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
